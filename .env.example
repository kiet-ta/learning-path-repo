# ============================================================
# Auto Learning Path Generator — Environment Configuration
# Copy this file to .env and fill in your values.
# NEVER commit .env to version control.
# ============================================================

# ── AI / NLP ─────────────────────────────────────────────────
# OpenAI API key (required for AI-powered analysis via ai-service)
OPENAI_API_KEY=sk-your-key-here

# LLM model to use (default: gpt-4o-mini for cost efficiency)
MODEL_NAME=gpt-4o-mini

# ── Database ──────────────────────────────────────────────────
# SQLite database path.  Format: sqlite:///relative/path.db
# For Docker: sqlite:///data/learning_path.db
DATABASE_URL=sqlite:///data/learning_path.db

# ── Repository Scanner ────────────────────────────────────────
# Root path to scan for git repositories (used by /api/v1/scan)
REPO_SCAN_PATH=/path/to/your/repos

# Maximum directory depth during scanning (1–20)
SCANNER_MAX_DEPTH=10

# Maximum file size in MB before a file is considered binary and skipped
SCANNER_MAX_FILE_SIZE_MB=10.0

# ── API Server ────────────────────────────────────────────────
# Host and port for the FastAPI server
HOST=0.0.0.0
PORT=8000

# Log level: DEBUG | INFO | WARNING | ERROR | CRITICAL
LOG_LEVEL=INFO

# ── Performance ───────────────────────────────────────────────
# Requests slower than this threshold (ms) will emit a WARNING log
SLOW_REQUEST_THRESHOLD_MS=2000

# ── CORS ─────────────────────────────────────────────────────
# Comma-separated list of allowed origins (use * for dev only)
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:5173

# ── AI Service (microservice) ─────────────────────────────────
# URL of the ai-service FastAPI microservice
AI_SERVICE_URL=http://localhost:8001

# ── Optional: Frontend Build ──────────────────────────────────
# Set to "true" to serve the Vite-built frontend at /
SERVE_STATIC=false
